{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Grishma5278/Info-5731/blob/main/Tallapareddy_Grishma_Exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 4**\n",
        "\n",
        "**This exercise will provide a valuable learning experience in working with text data and extracting features using various topic modeling algorithms. Key concepts such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "\n",
        "**Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e372dfb5-70f2-41cd-bbaa-622520beee57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['For reference, here are my ratings for the other movies: Despicable Me - 9 '\n",
            " 'stars. Despicable Me 2 - 8 stars. Minions - 6 stars. Despicable Me 3 - 7 '\n",
            " 'stars.I am so pleasantly surprised that this is the best one since the '\n",
            " 'original. It fires on all cylinders: comedy, story, visuals, action scenes. '\n",
            " 'It starts out fast and never lets up. The movie flies by. And it has tons of '\n",
            " 'great new characters.This movie is absolutely hilarious. I was literally in '\n",
            " 'tears in some scenes. The minions are at their very best with so many '\n",
            " 'memorable moments. The story is surprisingly unpredictable and keeps you '\n",
            " 'invested. The visuals are stunningly beautiful. I was mesmerized. And the '\n",
            " 'action scenes are pretty epic, the best of the entire series.I had a blast '\n",
            " \"with this movie. It's definitely worth seeing on a premium screen, greatly \"\n",
            " \"enhancing the visuals and action scenes.P. S. I'm not sure what's up with \"\n",
            " 'all these sarcastic 10 star reviews. I assure you this is not one of them. '\n",
            " '(2 viewings, opening Thursday IMAX 6/30/2022, IMAX 7/6/2022)',\n",
            " 'Going to watch \"future best animated picture winner\" Minions:Rise of Gru I '\n",
            " 'had high hopes. I was not however expected the experience that I had. The '\n",
            " 'Story was crisp and emotional, the animations though fake felt realer than '\n",
            " \"ever,I say this with no exaggeration.....IT WAS BETTER THAN MORBIUS. It's \"\n",
            " \"Morbin time...More like It's Minion Time.\",\n",
            " \"'Minions: The Rise of Gru' follows 11 3/4 year old Gru (voiced by Steve \"\n",
            " 'Carrell) trying to make a name for himself and join the ranks of an elite '\n",
            " 'villians group, the Vicious 6. With humble beginnings as a troublemaker in '\n",
            " \"his mother's basement, the minions (voiced by Pierre Coffin) are determined \"\n",
            " 'to help him succeed in his mission.The film is a sort of origin story for '\n",
            " 'Gru, despite having elusions to his childhood in the 1st and 3rd movies. The '\n",
            " 'wacky and wonderful minions carry the film, but sadly, the plot seems '\n",
            " 'haphazard. The henchmen, Jean-Clawed (voice by Jean-Claude Van Damme), '\n",
            " 'Svengeance (voiced by Dolph Lundgren), and Stronghold (voiced by Danny '\n",
            " 'Trejo) all seem to be second-string compared to Belle Bottom (voiced by '\n",
            " 'Taraji P. Henson) and Wild Knuckles (voiced by Alan Arkin). The animation is '\n",
            " \"fairly standard of the earlier movies, the flow is solid, and the film's \"\n",
            " 'ending kind of makes sense, but the plot in general is a bit of a '\n",
            " 'hodgepodge.Worth a watch with the kids.',\n",
            " \"This movie has so many references to the sixties and seventies that I don't \"\n",
            " 'think people under twenty will understand the puns, innuendos and jokes. The '\n",
            " 'children in the theater will still laugh at the slapstick jokes.',\n",
            " 'Its a fun movie. Minion scenes are more than Gru and thankfully so. The '\n",
            " 'chemistry between minions characters is epic. Love Kevin, Bob and '\n",
            " 'Stuart.There is no deep meaning or higher message, a simple carefree movie '\n",
            " 'which is supposed to be seen that way.',\n",
            " 'In his world, Gru is the most powerful villain anyone has ever seen. But the '\n",
            " 'question is: how did he become this dominant force? Minions: The Rise of Gru '\n",
            " 'shows us the exciting story of 12-year old Gru and the path to his '\n",
            " 'villainous life. Both the familiar faces and the new characters come '\n",
            " 'together to make this make this film highly entertaining, yet '\n",
            " 'nostalgic.Minions: The Rise of Gru provides the backstory for how Gru (Steve '\n",
            " 'Carell) came to be the notorious villain he is today. After being rejected '\n",
            " 'as a replacement for Wild Knuckles (Alan Arkin) and failing to earn a '\n",
            " 'much-coveted spot in the supervillain group Vicious 6, Gru unexpectedly '\n",
            " \"finds himself on the run. As fate would have it, Gru's dream of being \"\n",
            " 'mentored by Wild Knuckles soon comes true, but not without Gru having to now '\n",
            " 'lean on Wild Knuckles and his minions to fight back against the Vicious '\n",
            " '6.The three main minions-Kevin, Stuart, and Bob-each have unique character '\n",
            " 'traits that make these films work. In Minions: The Rise of Gru, you can see '\n",
            " 'how each minion plays a different role in how Gru grows as a villain and as '\n",
            " 'a person. Kevin is the smart and responsible leader-he makes sure everything '\n",
            " 'is going according to plan. Stuart is the one who is always in touch with '\n",
            " 'reality, and makes sure the truth is known-he may seem uninterested, but '\n",
            " \"he's very helpful. Bob is the lighthearted and innocent soul who always \"\n",
            " 'tries to make the best out of a situation. Without all three of these '\n",
            " \"characters, this movie wouldn't be the same. There are many subtle \"\n",
            " 'references to the previous movies that add to the comedic tone, as well. For '\n",
            " 'instance, in the scene where Gru and Wild Knuckles attempt to rob the bank, '\n",
            " 'the bank president shows them an image of his grandson, who turns out to be '\n",
            " \"none other than the aspiring villain, Vector. Of course, young Gru isn't \"\n",
            " 'aware that Vector will play a big role in his future, but the audience '\n",
            " 'definitely is. These subtle references are what contribute to the nostalgic '\n",
            " \"feel we get from watching this film. And, of course, we can't forget about \"\n",
            " \"Gru's iconic wardrobe, which he's already wearing as a young kid.The message \"\n",
            " 'of Minions: The Rise of Gru is that everyone needs a little help sometimes. '\n",
            " \"Even though he doesn't realize it right away, Gru eventually recognizes that \"\n",
            " 'he needs help in order to be the successful villain he desires to '\n",
            " 'be.Minions: The Rise of Gru is such a fun movie to watch. The lovable '\n",
            " 'characters just make the audience continue to yearn for more. I give it 5 '\n",
            " 'out of 5 stars and recommend it for ages 5 to 12, though anyone can enjoy '\n",
            " 'this movie. Minions: The Rise of Gru releases in theaters on July 1, 2022. '\n",
            " 'Make sure you check it out! By Maica N., KIDS FIRST!',\n",
            " \"I'm not sure why this movie doesn't have a higher rating, because i found it \"\n",
            " 'really enjoyable and much better than the first outing.Lets start with the '\n",
            " \"few negatives i have to say, because there aren't many. First the head \"\n",
            " 'female villain is a little annoying. Also there could do with a little bit '\n",
            " 'more emotion so we appreciate the humour even more. These things are '\n",
            " 'nitpicky though, as for the most part this is great fun.Lets now take it for '\n",
            " 'what it is; a comedy animation aimed mostly at kids. So, is it animated '\n",
            " \"well? Yes, it's one of the clearest most colourful animations i think i have \"\n",
            " \"ever seen. Is it funny? Yes, in fact it's very funny. I laughed many times \"\n",
            " \"throughout, proving you don't have to eve use proper words to be funny. Mr \"\n",
            " 'Bean is a prime example of that, and so here are the minions. Lastly will '\n",
            " 'kids get bored? Absolutely not. The story, (although with limited payout) '\n",
            " 'moves along at such a great pace, the movie felt really short and the '\n",
            " 'minions are so consistently funny, kids will never get tired of it and '\n",
            " 'actually neither will the big kids (adults).Finally i still maintain, there '\n",
            " 'is nothing cuter in this world than Bob and when he does his pleading face, '\n",
            " 'is like a puppy X100.A last though is that if they want to keep this '\n",
            " 'franchise alive though, i think they need to move onto shorts, because that '\n",
            " 'will it will stop it becoming too repetitive and boring.',\n",
            " 'It may feel in total like this franchise is running out of steam, or at '\n",
            " 'least fresh and creative ideas- but Minions The Rise of Gru does manage to '\n",
            " 'be decently entertaining and charming enough to be worth at least a one time '\n",
            " 'watch. A lot of people, critics included, bash the 2015 film Minions for a '\n",
            " 'lack of a true plot among many other things- but in my personal opinion I '\n",
            " 'actually enjoyed the first minions movie and may even find it better than '\n",
            " 'this one. Although both films are flawed, Minions had a very clear although '\n",
            " 'frantic vision set in mind for ts characters- and never felt like a '\n",
            " 'combination of two completely different films like this one did. So what is '\n",
            " 'it about this film that makes it worth watching? Well the animation for one '\n",
            " 'is absolutely fantastic, gorgeous visuals that are easily the best to ever '\n",
            " \"come out of Illumination in their company's entire run. Kid Gru is also a \"\n",
            " \"fun and charming lead, and i'll be darned if the minions silly gags didn't \"\n",
            " 'charm me from time to time and even earn a chuckle or two (the airplane '\n",
            " 'scene most of all). Its plot is truly all over the place, much like the '\n",
            " 'first film, and its focus on characters feels very divided- as well as its '\n",
            " 'focus on future characters come to be in the franchise considering and '\n",
            " \"reminding the audience how this is a prequel- in case the 70's vibes \"\n",
            " \"wouldn't tell you otherwise. I don't know, its entertaining it has its \"\n",
            " 'moments and I found some fun in it. Its an uneven little flick but its use '\n",
            " 'of colorful visuals and fun characters make it decent enough for a pleasant '\n",
            " 'experience- and certainly trumps the third Despicable Me film and latest '\n",
            " \"franchise release before this one almost 5 years ago. It's hard to believe \"\n",
            " 'this franchise is still going, and how it still manages to propel itself '\n",
            " 'forward, but in this age of commercialization and franchises- Minions the '\n",
            " 'Rise of Gru can be more tolerable than most.My Rating: 6.2/10.',\n",
            " 'The reason The Rise of Gru feels like such a let down is because it lacks '\n",
            " \"creativity, there's not enough of minions, but there's not enough of the \"\n",
            " \"young Gru either. That's not to say it isn't a movie families with young \"\n",
            " \"children will have fun watching, but compared to this movie's predecessor \"\n",
            " 'and all the Despicable Me movies so far, The Rise of Gru is probably the '\n",
            " 'flattest of each of them.Directed by Kyle Balda from a story written and '\n",
            " 'co-thought by Matthew Fogel, this Minions movie brings back Steve Carrell to '\n",
            " 'voice the child-version of the \"superbad-superdad\" Gru and Pierre Coffin as '\n",
            " 'the minions to a setting during the 1970s and behind the Despicable Me '\n",
            " 'movies. If you are a Despicable Me fan or just appreciate the original '\n",
            " 'movies, this film offers a delightful set of hilarious references and other '\n",
            " \"jokes that'll have the whole family laughing. The typical requirements for \"\n",
            " 'animated movies such as voices, animation and other things all work out well '\n",
            " 'in this movie.However, for a Despicable Me prequel titled Minions: The Rise '\n",
            " 'of Gru, this film sure lacks a fair amount of time to laugh with the '\n",
            " \"minions, and the child Gru doesn't have enough of a story or motive behind \"\n",
            " 'him that keeps us fully appealed to the story. This film also follows the '\n",
            " 'predictable Despicable Me basis of having protagonists working with their '\n",
            " \"own lives, but then there's the threat by the villain/s. And this movies \"\n",
            " \"group of villains may be funny, but they're completely unoriginal, leading \"\n",
            " 'to the plot to be quite bland.If you liked this review, check out the full '\n",
            " 'review and other reviews at aussieboyreviews.',\n",
            " \"Join Gru and the Minions in the sequel that's actually better than the \"\n",
            " \"first! It's fun for kids, teens, adults, and seniors! Let's make this film \"\n",
            " \"gross $1 trillion in the freaking box office, y'all!\",\n",
            " \"Just loved it, the whole time! There is no time to get bored at all, it's \"\n",
            " 'full of well-made action and really funny stuff, and the minions are truly '\n",
            " 'lovely.',\n",
            " 'The latest from Illumination Studios is another adventure, actually a '\n",
            " 'prequel this time, as we follow how Gru, still voiced by Steve Carrell, '\n",
            " 'tries to get in the door to join the Vicious Six (voiced by Alan Arkin, '\n",
            " 'Taraji P. Henson, Jean Claude Van Damme, Lucy Lawless, Danny Trejo & Dolph '\n",
            " 'Lundrgren) after they have betrayed Arkin during a sacred stone heist. '\n",
            " 'Dismissing him as being too young & distracted by another potential try-out, '\n",
            " 'Gru manages to steal the stone sending the baddies on his tail but due to '\n",
            " 'one of the accompanying minions trading the stone out for a pet rock, the '\n",
            " 'race is on to get the rock back before the Vicious Six (really five at this '\n",
            " 'point!) get their collective mitts on it. Sure the film is threadbare '\n",
            " 'plotwise (being an excuse to have a bunch of minion antics running '\n",
            " 'throughout the story like socks on a laundry line) but the film is nothing '\n",
            " 'but fun & unlike the Shrek films which acted as an alternative to the Pixar '\n",
            " 'output, at least the Illumination team keeps pushing the envelope on '\n",
            " \"perfecting their visuals (standouts include the textures on the minions' \"\n",
            " \"goggles & Gru's realistic expressions when he's upset or challenged). \"\n",
            " \"Returning champs to the franchise include Julie Andrews as Gru's mom, \"\n",
            " \"Russell Brand as Mr. Nefario (he's not a doc yet) w/Michelle Yeoh as a kung \"\n",
            " 'fu master the minions get lessons from & the Rza as a biker who gives a '\n",
            " 'minion a much needed ride to San Francisco.',\n",
            " 'Minion: The Rise of GruWhat a disappointment this was, and quite frankly I '\n",
            " 'was bored from start to finish!Yet again the script writers have failed to '\n",
            " 'glean from the original movie what was the magical element that made this '\n",
            " 'franchise a success. Clearly is was the strength of story, brilliant and '\n",
            " 'inventive animation, and well drawn and memorable characters. Here the story '\n",
            " \"was tissue thin, Gru's family was all but missing, there was little reason \"\n",
            " 'for things to happen, and the animation was largely uninventive with just '\n",
            " 'repetition from earlier movies.What was key in the original movie what the '\n",
            " 'strong relationship ties between the characters, at best they were casual '\n",
            " 'acquaintances in this movie.Nobody liked it except the children who seem '\n",
            " 'mesmerised by the Minions, clearly easily pleased.For me this is a 5 outta '\n",
            " '10, barely a screensaver!',\n",
            " 'All trolling aside, this movie was very average and below average as far as '\n",
            " 'kids movies go. The animation is top notch but at this point the minions '\n",
            " 'pretty much have the same jokes in every movie. You know what to expect '\n",
            " \"here, there's nothing new. Kids will love it and parents will probably still \"\n",
            " 'hate it, although it might bring out a couple chuckles with some sly adult '\n",
            " 'jokes. The animation carries this film.',\n",
            " 'Nothing too impressive or new.. Te scenes look contrived. Learning kung-fu '\n",
            " 'scenes were an utter waste of time. Too slapstick even for kids. Hope there '\n",
            " 'will be a better storyline next time.',\n",
            " \"LIKES:The References: If you've read my reviews before, you'll know I'm a \"\n",
            " 'sucker for easter eggs and references to other genres of Hollywood. The '\n",
            " 'second installment of Minions was a delight in this avenue, loaded with nods '\n",
            " 'to various movies and their scenes that made them famous. From the opening '\n",
            " 'scene where we revisit Indiana Jones temple run to the Kung Fu movies that '\n",
            " 'made the 60s-80s so much fun, its these references that a movie goer like me '\n",
            " \"enjoys. It's enjoyable to see the dynamics unfold, and I loved taking a trip \"\n",
            " 'back into this twisted memory of videos I watched as a kid. I found this to '\n",
            " 'be a part adults will like, and a way to open up to other audiences past the '\n",
            " 'target age.The Voice Acting: Part of the fun of animated features is the '\n",
            " 'voice actors who make the cartons and CGI models come to life and add that '\n",
            " 'emotion. Minions: Rise of Gru is loaded with talent, pulling a wide variety '\n",
            " 'of voices that leads to fun characters and new voices for your little ones '\n",
            " 'to impersonate. The Vicious 6, the collective bunch of baddies has stellar '\n",
            " 'talent in the form of those iconic actors that seem to be background voices '\n",
            " 'like Dolph Lundgren, Danny Trejo, and Lucy Lawless are just some of the '\n",
            " 'voices that you will hear, and though not the most prominent, they still '\n",
            " 'have a great place in this film. Others like Taraji P. Henson and Michelle '\n",
            " 'Yeoh have bigger roles and get that sass factor you love in the characters '\n",
            " 'of this goofy world. And there are other characters reviving their parts '\n",
            " 'like Russell Brand and Julie Andrews who though short and sweet do it so '\n",
            " 'well. Yet the main voices are the top billed cast and they work the real '\n",
            " 'charm in this movie. Arkin as White Knuckle is pretty much playing his live '\n",
            " 'action roles in an animated form and it works as the jokes, threats, and '\n",
            " 'warming moments feel genuine and caustic like the old age jokes he often is '\n",
            " 'the butt of. Pierre Coffin is still the energetic and hyper voice of the '\n",
            " 'various yellow blobs that are the Minions. Though they sound very much the '\n",
            " 'same, Coffin manages to really work personalities into the four main guys to '\n",
            " \"stand out and work with the physical personas that they wear so well. It's a \"\n",
            " 'subtle thing for audience members like me, but I appreciate the effort to '\n",
            " 'make them stand out a bit more. As for Carrell, he rocks the Gru voice he '\n",
            " 'invented so well, but this time changes the pitch to sound like a kid '\n",
            " 'version of Gru we saw in the original. And yet this time, more charm and '\n",
            " 'emotion were seen and it worked very well to craft more of the evil '\n",
            " \"villain's formative years to explain so much. All in all, the acting is \"\n",
            " 'stacked and well executed and I quite enjoyed how well they played '\n",
            " \"together.The Pace: It's a kids movie, so you can expect that the movie is \"\n",
            " 'going to be very quick paced and not standing still too much. However, Rise '\n",
            " 'of Gru manages to still harness that speed and tone it down to give you '\n",
            " 'those moments that allow for character development and training without '\n",
            " 'blowing it over completely. True, the movie does not quite have the balance '\n",
            " 'or natural layout of Despicable Me, but for a sequel of a prequel, the '\n",
            " 'balance is quite welcome and perfectly fit for the other components put into '\n",
            " 'the movie.The Music: The Gru legacy is chock full of music from the various '\n",
            " 'decades that fans dive into no matter what age you currently are. In this '\n",
            " 'prequel , the trend continues with some orchestra work present to help out '\n",
            " \"the emotional moments, it's the tracks they put in that are my favorite to \"\n",
            " \"tap my toes to. Gru's gang has plenty of decade classics, and other songs \"\n",
            " 'that need to fill the void are brought out by the Minions cover, giving you '\n",
            " 'that comedic edge to the film.The Animation/Design Now we get into the '\n",
            " 'levels that are the main strengths for me in this film. Illumination may not '\n",
            " 'be groundbreaking in terms of animation and design, but they certainly did '\n",
            " 'accomplish fluid movement and that loveable, kid friendly, structure that we '\n",
            " \"fell in love with years ago. Gru's adventures are still whacky and the \"\n",
            " 'extreme features they share are still all utilized well to make that '\n",
            " 'caricature design I love, but helping incorporate some other cultural moves '\n",
            " 'into the works as well. The martial arts montage shows how they keep putting '\n",
            " 'new features into the design and again it works so well to make this '\n",
            " 'adventure enjoyable.The Balance Somewhat: Minions 2 had a lot of things to '\n",
            " 'juggle and three plot lines to leap about to make the adventure whole. It '\n",
            " 'worked for the most part at least for two of the stories that they were '\n",
            " \"working on. You'll get plenty of screen time between the classic three and \"\n",
            " \"Gru's adventure as they each work to the ultimate goal of being the ultimate \"\n",
            " 'villain of the era. The gimmicks are cute, and each story has its own feel '\n",
            " 'to it that are grossly different, but yet connect like an ionic bond to make '\n",
            " 'something stronger. The other plot line is attempting to incorporate a new '\n",
            " 'character, and while a little heartwarming, is primarily comedic antics that '\n",
            " 'will end up in some way, shape and form in the form of a toy. Nevertheless, '\n",
            " 'many of these plot lines do well to get adequate time and that kept things '\n",
            " 'dynamic and fun.The Comedy: I laughed a lot in this film, the balance of '\n",
            " 'adult humor and kid humor tickling my funny bones a lot as they vied to find '\n",
            " 'their place in the writing. Rise of Gru may not be quite as clever or '\n",
            " 'cultured as the Despicable Me movie from long ago, but it still has plenty '\n",
            " 'of pizazz and well-timed moments to get you busting out a hardy chuckle or '\n",
            " 'guffaw. Slapstick comedy, physical humor, pronunciation of words, and some '\n",
            " 'clever lines all have a nice mix into the run time, always keeping the '\n",
            " 'atmosphere and energy of the film in check.The Fun: Overall though, I had a '\n",
            " 'lot of fun in this film, and managed to find it better than several of the '\n",
            " \"other entries in this film. Gru's childhood had a lot of quirks to it, but \"\n",
            " 'overall there was a lot of heart and adventurous energy that just made going '\n",
            " 'to the movies fun. Another group in my showing seemed to agree, and all the '\n",
            " 'comedic moments and Minion squeaks should fill your theater with laughter '\n",
            " 'and delight. Not too many politics, not getting lost in some cultural '\n",
            " \"relevance that films seem to want to explore, and it's not going too deep or \"\n",
            " 'surreal to complicate matters. This film is just another enjoyable venture '\n",
            " 'that helps you take a break from the harsh reality of '\n",
            " 'today.DISLIKES:Predictable Plot: The trailers have a lot to do with this, '\n",
            " 'but the movie, to no surprise, is a predictable mess that is a bit boring. I '\n",
            " 'know, I should not have expected something like that, but Disney has proven '\n",
            " 'to pull that twist on us when it counts to shock us to the core. Minions: '\n",
            " 'Rise of Gru could have tried to add a few more kinks into the mix, which '\n",
            " 'might have helped add that little bit of adventure that the first one did '\n",
            " 'long ago.More Balance Needed In Characters: You know me and my utilizing '\n",
            " 'characters well if you are going to include them. Rise of Gru does an okay '\n",
            " \"job on about a handful of characters, but I can't help but feel there were \"\n",
            " 'too many new contenders to the mix to say they were all crucial to the plot. '\n",
            " 'The main antagonists were unimpressive and certainly could have been paired '\n",
            " 'or sent out on other missions to help give them more dimension than the '\n",
            " 'stereotypes they served as. Meanwhile, Brand and Andrews characters were '\n",
            " 'very scarce, maximizing their time, but really not having a leg in the race '\n",
            " 'like I had hoped they would. And even the new Minion did not quite shine '\n",
            " 'like the original trio, meaning he was pretty much for toys than running '\n",
            " 'with his boys, which again was a shame.Could Have Used A Little More '\n",
            " 'Heartwarming Moments: The first two movies had those touching moments that '\n",
            " 'really dug into your hearts and pulled the family card out for you to enjoy. '\n",
            " 'However, Minions 2, while trying, did not quite have the same awwwww moments '\n",
            " \"you might be looking for. Don't get me wrong, there are still cute moments \"\n",
            " 'to be had, some as trades to get the joke in, and there are those hints of '\n",
            " 'something deeper happening. Yet, this films balance towards the character '\n",
            " 'side did not quite come off as clean as the previous installments.Sort of '\n",
            " 'Disconnected At Times: Finally, the movie feels not quite as linear and '\n",
            " 'connected as the other films have had in the past. Whether it was due to '\n",
            " 'delays, or the fear of too much story, this sequel-prequel has moments that '\n",
            " 'feel like something was dropped or edited down to get to the end game '\n",
            " 'faster. While it is subtle at times, there is just something missing that '\n",
            " \"feels like a Director's cut is needed for home release.The VERDICT:\\n\"\n",
            " 'The claims of the movie being the funniest of the year is at least partially '\n",
            " 'true. Minions: Rise of Gru is by far the same spectacle you have come to '\n",
            " 'expect with bright animation, lots of music, references that are great for '\n",
            " 'guys like me and great voice acting that makes them come to life. Sure it '\n",
            " 'has some predictability issues, and character inclusion/balance is not '\n",
            " 'perfect leading to a disconnected feeling that the first two movies did '\n",
            " 'better. Yet, the movie is still super fun and accomplishes the task of not '\n",
            " 'being political and just being a movie to lose yourself in for a few hours. '\n",
            " 'When all of this is said and done, the movie for me gets a thumbs up for '\n",
            " 'theater watching if you can, and with that my scores '\n",
            " 'are:Animation/Adventure/Comedy: 8.0\\n'\n",
            " 'Movie Overall: 7.0.',\n",
            " 'This is by far the best movie of the year! Id say it even competes with The '\n",
            " \"Godfather it's that amazing! The cinematography, the dialogue with the \"\n",
            " \"Minions and Gru, it's fantastic! This movie is an emotional roller coaster \"\n",
            " 'with genius directing. This is a must watch movie for all generations and I '\n",
            " 'highly recommend!',\n",
            " 'Was pretty excited about this one after seeing the trailer. But it was just '\n",
            " 'disappointing. Me and my kids went (and also to the original Minions 1 '\n",
            " 'movie) and it was just ok. They had fun... but their standards for movies is '\n",
            " 'pretty low.It looked great.. but the story and characters just felt so '\n",
            " 'boring and flat. Jokes were just ok.. mostly flat here as well. Just felt a '\n",
            " \"bit all over the place and didn't click for us. They could have done so much \"\n",
            " 'better with this movie.. just disappointing.',\n",
            " 'The backstory was interesting and watching young gru was.. an experience and '\n",
            " \"the whole Chinese new years theme seemed a bit random but STILL IT'S MINIONS \"\n",
            " 'so I give it 10 stars. Bob was so adorable as usual and I loved how they '\n",
            " 'added Otto in this movie.',\n",
            " 'After the last of the Minions movies, Despicable Me 3, I thought the '\n",
            " 'adorable critters had stayed too long at the party. The sequel dropoff had '\n",
            " 'been trending, reaching low enough for a mercy killing. So when I saw that '\n",
            " \"there was another round coming - a prequel of Gru's origin story, I entered \"\n",
            " 'the theater with trepidation. SURPRISE!! This one may be the funniest of the '\n",
            " 'series! New writers apparently did the trick. Well, Matthew Fogel is new to '\n",
            " 'the franchise, and Brian Lynch is returning after penning the relatively '\n",
            " 'amusing Minions in 2015. They give us Gru at age 11, aspiring to be a '\n",
            " 'supervillain and already variably helped and plagued by his little yellow '\n",
            " 'pals. He gets the chance to join a quintet of his megavillain heroes when '\n",
            " \"the vacancy they'd just created by ousting the sixth member opens the \"\n",
            " \"selection for his replacement. They shun him just because he's a kid \"\n",
            " 'inspiring him to turn the tables on them to prove his worth. The plot '\n",
            " 'borrows from the Indiana Jones legacy and slips in homages to Kung Fu flicks '\n",
            " 'and many other pop-culture figures and themes, set in1976, mostly in San '\n",
            " \"Francisco.The more of those movies you've seen - live action or animated - \"\n",
            " \"the more you'll find to enjoy here. For example, one of the evildoers has a \"\n",
            " 'huge crablike right arm. Not only is he named Jean-Clawed, but Mr. Van Damme '\n",
            " 'actually provides his voice! Steve Carrell returns as Gru, assisted by the '\n",
            " 'likes of Michelle Yeoh, Lucy Liu, Alan Arkin, Danny Trejo and Julie-freakin '\n",
            " \"- Andrews! That's establishing a cast pedigree that the script serves \"\n",
            " 'dutifully.Besides the job they did of packing lots of laughs into the dialog '\n",
            " 'and rapid-fire action, there are goodies to savor in the backgrounds ala The '\n",
            " 'Simpsons. Art design is first-rate, with a wealth of colors and characters '\n",
            " 'to tickle viewers of all ages. No animation corps ever used San Francisco to '\n",
            " 'better advantage, making the city and Bay Area look gorgeous - especially '\n",
            " 'Chinatown. This is one of those rare films worth seeing twice, since so much '\n",
            " \"is going on so quickly that I'm sure I missed a number of gags. Don't just \"\n",
            " 'drop the kids at the theater for this one. Join them.',\n",
            " \"I've been waiting since Despicable Me 2 for the makers of the Minions to \"\n",
            " 'make another good movie in the franchise. After seeing Minions: The Rise of '\n",
            " \"Gru I think I'll have to keep waiting. This movie isn't as trashy and \"\n",
            " \"terrible as the last 2 movies with Minions, but it's not anything special. I \"\n",
            " 'always have a slight issue with any of these movies because having an '\n",
            " \"aspiring villain as your protagonist is such a challenge. It's hard for me \"\n",
            " \"to cheer for a young Gru to become more evil, and I'm not even sure how the \"\n",
            " 'logic of the villains even works. It seems like the minute Gru gets the '\n",
            " 'better of the Vicious 6 they would consider him a great villain, yet they '\n",
            " 'instead form this vendetta against him. It just never works for me living in '\n",
            " 'these opposite worlds where bad is good, and good is bad, particularly with '\n",
            " \"such loveable and fun-loving minions. There's a lack of any consistency, and \"\n",
            " \"even if I get a chuckle out of it, I don't think it's the best kind of \"\n",
            " 'story-telling.I still think that the Minions are better in smaller doses. '\n",
            " 'The long sequences with just Minions and them learning kung fu is only cute '\n",
            " 'for a few minutes and starts to get tedious as they go on. I also struggle '\n",
            " \"every single time I watch a prequel. I don't understand Hollywood's \"\n",
            " 'fascination with making them, and just like any other prequel, they make a '\n",
            " 'point of shining a spotlight on things that are in the original movies. \"Oh '\n",
            " 'look, it\\'s Dr. Nefario!\" \"Now there is that bank manager guy, I know him!\" '\n",
            " \"It's not good story-telling, and fails to have a purpose for people who \"\n",
            " \"aren't overly familiar with the first film. There is a lot of negativity in \"\n",
            " \"this review, but I want to make it clear I didn't hate seeing this movie. \"\n",
            " 'Minions: The Rise of Gru was good for some laughs, particularly in the big '\n",
            " \"climax. I don't hate the Minions as much as some other people do, and I \"\n",
            " 'wanted to enjoy this as much as I liked Despicable Me or even Despicable Me '\n",
            " '2. It was underwhelming, but considering where the franchise has gone, this '\n",
            " 'was at least a little more enjoyable.',\n",
            " 'If you have kids and want to be like a kid. Go\\n'\n",
            " 'See this movie. Better yet, take a matinee show where you will be with other '\n",
            " 'kids.This movie has everything.From start to end, I loved the movie.And yes, '\n",
            " 'my kids loved it too.Make sure to take popcorn with you.What do you want to '\n",
            " 'be when you grow up?I want to be a super villain!',\n",
            " \"Take this for what it is, I am a late 40's guy watching this. And that is my \"\n",
            " 'fault. However, this is set in 1976, so I remember a tiny bit of it. '\n",
            " 'Anachronisms a plenty. But, that said, this the return of some little yellow '\n",
            " 'pilled gibberish spewing...things. I did watch \"Despicable Me\" years ago, '\n",
            " \"but can't fully remember what that was about. This one is Gru attempting to \"\n",
            " 'join a super villain coalition. This coming during the Chinese New Year. A '\n",
            " 'jade amulet holds the answer to his entry into the world of villainy. So he '\n",
            " 'desperately wants to be accepted by his fellow baddies. Cool cameo voices by '\n",
            " 'Jean Claude Van Damme, Julie Andrews and Dolph Lundgren. However, through so '\n",
            " 'much audio processing, they may as well be anyone.This is so mediocre. Tired '\n",
            " 'tropes of Minions rambling a language between Portuguese and French. Hard to '\n",
            " \"say. But a few cute moments don't save a movie that seems so...template \"\n",
            " \"built.The noise and butt jokes will be amusing for the kids. The 70's \"\n",
            " \"references will placate the Gen X'ers.\"]\n"
          ]
        }
      ],
      "source": [
        "import requests, csv\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "url = \"https://www.imdb.com/title/tt5113044/reviews?ref_=tt_urv\"\n",
        "data = requests.get(url)\n",
        "soup = BeautifulSoup(data.content, 'html.parser')\n",
        "\n",
        "imdb_reviews=[]\n",
        "right_table=soup.find('div', {'class':\"lister\"})\n",
        "for i in right_table.findAll('div', class_=\"lister-item mode-detail imdb-user-review collapsable\"):\n",
        "  imdb_reviews.append(i.find(\"div\", class_=\"text show-more__control\").text.strip())\n",
        "pprint(imdb_reviews)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'reviews': imdb_reviews})\n",
        "\n",
        "df.to_csv('reviews.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-KhyzZIdYW07",
        "outputId": "1fc420c7-88a3-4134-813a-571d90a7aabf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             reviews\n",
              "0  For reference, here are my ratings for the oth...\n",
              "1  Going to watch \"future best animated picture w...\n",
              "2  'Minions: The Rise of Gru' follows 11 3/4 year...\n",
              "3  This movie has so many references to the sixti...\n",
              "4  Its a fun movie. Minion scenes are more than G..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c7ef3d5-2993-4224-8e7f-9edafa640d4b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For reference, here are my ratings for the oth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Going to watch \"future best animated picture w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Minions: The Rise of Gru' follows 11 3/4 year...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This movie has so many references to the sixti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Its a fun movie. Minion scenes are more than G...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c7ef3d5-2993-4224-8e7f-9edafa640d4b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c7ef3d5-2993-4224-8e7f-9edafa640d4b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c7ef3d5-2993-4224-8e7f-9edafa640d4b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96ea9e85-8768-4af4-be12-8c6718a0ff32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96ea9e85-8768-4af4-be12-8c6718a0ff32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96ea9e85-8768-4af4-be12-8c6718a0ff32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"reviews\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"LIKES:The References: If you've read my reviews before, you'll know I'm a sucker for easter eggs and references to other genres of Hollywood. The second installment of Minions was a delight in this avenue, loaded with nods to various movies and their scenes that made them famous. From the opening scene where we revisit Indiana Jones temple run to the Kung Fu movies that made the 60s-80s so much fun, its these references that a movie goer like me enjoys. It's enjoyable to see the dynamics unfold, and I loved taking a trip back into this twisted memory of videos I watched as a kid. I found this to be a part adults will like, and a way to open up to other audiences past the target age.The Voice Acting: Part of the fun of animated features is the voice actors who make the cartons and CGI models come to life and add that emotion. Minions: Rise of Gru is loaded with talent, pulling a wide variety of voices that leads to fun characters and new voices for your little ones to impersonate. The Vicious 6, the collective bunch of baddies has stellar talent in the form of those iconic actors that seem to be background voices like Dolph Lundgren, Danny Trejo, and Lucy Lawless are just some of the voices that you will hear, and though not the most prominent, they still have a great place in this film. Others like Taraji P. Henson and Michelle Yeoh have bigger roles and get that sass factor you love in the characters of this goofy world. And there are other characters reviving their parts like Russell Brand and Julie Andrews who though short and sweet do it so well. Yet the main voices are the top billed cast and they work the real charm in this movie. Arkin as White Knuckle is pretty much playing his live action roles in an animated form and it works as the jokes, threats, and warming moments feel genuine and caustic like the old age jokes he often is the butt of. Pierre Coffin is still the energetic and hyper voice of the various yellow blobs that are the Minions. Though they sound very much the same, Coffin manages to really work personalities into the four main guys to stand out and work with the physical personas that they wear so well. It's a subtle thing for audience members like me, but I appreciate the effort to make them stand out a bit more. As for Carrell, he rocks the Gru voice he invented so well, but this time changes the pitch to sound like a kid version of Gru we saw in the original. And yet this time, more charm and emotion were seen and it worked very well to craft more of the evil villain's formative years to explain so much. All in all, the acting is stacked and well executed and I quite enjoyed how well they played together.The Pace: It's a kids movie, so you can expect that the movie is going to be very quick paced and not standing still too much. However, Rise of Gru manages to still harness that speed and tone it down to give you those moments that allow for character development and training without blowing it over completely. True, the movie does not quite have the balance or natural layout of Despicable Me, but for a sequel of a prequel, the balance is quite welcome and perfectly fit for the other components put into the movie.The Music: The Gru legacy is chock full of music from the various decades that fans dive into no matter what age you currently are. In this prequel , the trend continues with some orchestra work present to help out the emotional moments, it's the tracks they put in that are my favorite to tap my toes to. Gru's gang has plenty of decade classics, and other songs that need to fill the void are brought out by the Minions cover, giving you that comedic edge to the film.The Animation/Design Now we get into the levels that are the main strengths for me in this film. Illumination may not be groundbreaking in terms of animation and design, but they certainly did accomplish fluid movement and that loveable, kid friendly, structure that we fell in love with years ago. Gru's adventures are still whacky and the extreme features they share are still all utilized well to make that caricature design I love, but helping incorporate some other cultural moves into the works as well. The martial arts montage shows how they keep putting new features into the design and again it works so well to make this adventure enjoyable.The Balance Somewhat: Minions 2 had a lot of things to juggle and three plot lines to leap about to make the adventure whole. It worked for the most part at least for two of the stories that they were working on. You'll get plenty of screen time between the classic three and Gru's adventure as they each work to the ultimate goal of being the ultimate villain of the era. The gimmicks are cute, and each story has its own feel to it that are grossly different, but yet connect like an ionic bond to make something stronger. The other plot line is attempting to incorporate a new character, and while a little heartwarming, is primarily comedic antics that will end up in some way, shape and form in the form of a toy. Nevertheless, many of these plot lines do well to get adequate time and that kept things dynamic and fun.The Comedy: I laughed a lot in this film, the balance of adult humor and kid humor tickling my funny bones a lot as they vied to find their place in the writing. Rise of Gru may not be quite as clever or cultured as the Despicable Me movie from long ago, but it still has plenty of pizazz and well-timed moments to get you busting out a hardy chuckle or guffaw. Slapstick comedy, physical humor, pronunciation of words, and some clever lines all have a nice mix into the run time, always keeping the atmosphere and energy of the film in check.The Fun: Overall though, I had a lot of fun in this film, and managed to find it better than several of the other entries in this film. Gru's childhood had a lot of quirks to it, but overall there was a lot of heart and adventurous energy that just made going to the movies fun. Another group in my showing seemed to agree, and all the comedic moments and Minion squeaks should fill your theater with laughter and delight. Not too many politics, not getting lost in some cultural relevance that films seem to want to explore, and it's not going too deep or surreal to complicate matters. This film is just another enjoyable venture that helps you take a break from the harsh reality of today.DISLIKES:Predictable Plot: The trailers have a lot to do with this, but the movie, to no surprise, is a predictable mess that is a bit boring. I know, I should not have expected something like that, but Disney has proven to pull that twist on us when it counts to shock us to the core. Minions: Rise of Gru could have tried to add a few more kinks into the mix, which might have helped add that little bit of adventure that the first one did long ago.More Balance Needed In Characters: You know me and my utilizing characters well if you are going to include them. Rise of Gru does an okay job on about a handful of characters, but I can't help but feel there were too many new contenders to the mix to say they were all crucial to the plot. The main antagonists were unimpressive and certainly could have been paired or sent out on other missions to help give them more dimension than the stereotypes they served as. Meanwhile, Brand and Andrews characters were very scarce, maximizing their time, but really not having a leg in the race like I had hoped they would. And even the new Minion did not quite shine like the original trio, meaning he was pretty much for toys than running with his boys, which again was a shame.Could Have Used A Little More Heartwarming Moments: The first two movies had those touching moments that really dug into your hearts and pulled the family card out for you to enjoy. However, Minions 2, while trying, did not quite have the same awwwww moments you might be looking for. Don't get me wrong, there are still cute moments to be had, some as trades to get the joke in, and there are those hints of something deeper happening. Yet, this films balance towards the character side did not quite come off as clean as the previous installments.Sort of Disconnected At Times: Finally, the movie feels not quite as linear and connected as the other films have had in the past. Whether it was due to delays, or the fear of too much story, this sequel-prequel has moments that feel like something was dropped or edited down to get to the end game faster. While it is subtle at times, there is just something missing that feels like a Director's cut is needed for home release.The VERDICT:\\nThe claims of the movie being the funniest of the year is at least partially true. Minions: Rise of Gru is by far the same spectacle you have come to expect with bright animation, lots of music, references that are great for guys like me and great voice acting that makes them come to life. Sure it has some predictability issues, and character inclusion/balance is not perfect leading to a disconnected feeling that the first two movies did better. Yet, the movie is still super fun and accomplishes the task of not being political and just being a movie to lose yourself in for a few hours. When all of this is said and done, the movie for me gets a thumbs up for theater watching if you can, and with that my scores are:Animation/Adventure/Comedy: 8.0\\nMovie Overall: 7.0.\",\n          \"Join Gru and the Minions in the sequel that's actually better than the first! It's fun for kids, teens, adults, and seniors! Let's make this film gross $1 trillion in the freaking box office, y'all!\",\n          \"For reference, here are my ratings for the other movies: Despicable Me - 9 stars. Despicable Me 2 - 8 stars. Minions - 6 stars. Despicable Me 3 - 7 stars.I am so pleasantly surprised that this is the best one since the original. It fires on all cylinders: comedy, story, visuals, action scenes. It starts out fast and never lets up. The movie flies by. And it has tons of great new characters.This movie is absolutely hilarious. I was literally in tears in some scenes. The minions are at their very best with so many memorable moments. The story is surprisingly unpredictable and keeps you invested. The visuals are stunningly beautiful. I was mesmerized. And the action scenes are pretty epic, the best of the entire series.I had a blast with this movie. It's definitely worth seeing on a premium screen, greatly enhancing the visuals and action scenes.P. S. I'm not sure what's up with all these sarcastic 10 star reviews. I assure you this is not one of them. (2 viewings, opening Thursday IMAX 6/30/2022, IMAX 7/6/2022)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk; nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrFSCN9cYcog",
        "outputId": "805e5f3f-8fa6-41b0-cc8f-31f4cbf20167"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import os\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "  !java -version\n",
        "install_java()\n",
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odHsdkdPYjdY",
        "outputId": "c7310d30-c456-4cd3-badb-ed4e6d73ba78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.22\" 2024-01-16\n",
            "OpenJDK Runtime Environment (build 11.0.22+7-post-Ubuntu-0ubuntu222.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.22+7-post-Ubuntu-0ubuntu222.04.1, mixed mode, sharing)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.4)\n",
            "Collecting pandas>=2.0.0 (from pyLDAvis)\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.9.0)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
            "Collecting tzdata>=2022.7 (from pandas>=2.0.0->pyLDAvis)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.4.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Installing collected packages: funcy, tzdata, pandas, pyLDAvis\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed funcy-2.0 pandas-2.2.1 pyLDAvis-3.4.1 tzdata-2024.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import lxml.html as LH\n",
        "import urllib.request as urllib2\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H18eal7EYvO-",
        "outputId": "157f156d-d42b-4d01-e5cb-8d3198dce5cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "orTPi0h_Y37B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc))\n",
        "             if word not in stop_words] for doc in texts]\n",
        "\n",
        "rev_data = df['reviews'].values.tolist()\n",
        "rev_data_words = list(sent_to_words(rev_data))\n",
        "rev_data_words = remove_stopwords(rev_data_words)\n",
        "print(rev_data_words[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwMzsm82Y8gR",
        "outputId": "e066f70a-c49d-4762-ee03-9453331e284a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['reference', 'ratings', 'movies', 'despicable', 'stars', 'despicable', 'stars', 'minions', 'stars', 'despicable', 'stars', 'pleasantly', 'surprised', 'best', 'one', 'since', 'original', 'fires', 'cylinders', 'comedy', 'story', 'visuals', 'action', 'scenes', 'starts', 'fast', 'never', 'lets', 'movie', 'flies', 'tons', 'great', 'new', 'characters', 'movie', 'absolutely', 'hilarious', 'literally', 'tears', 'scenes', 'minions', 'best', 'many', 'memorable', 'moments', 'story', 'surprisingly', 'unpredictable', 'keeps', 'invested', 'visuals', 'stunningly', 'beautiful', 'mesmerized', 'action', 'scenes', 'pretty', 'epic', 'best', 'entire', 'series', 'blast', 'movie', 'definitely', 'worth', 'seeing', 'premium', 'screen', 'greatly', 'enhancing', 'visuals', 'action', 'scenes', 'sure', 'sarcastic', 'star', 'reviews', 'assure', 'one', 'viewings', 'opening', 'thursday', 'imax', 'imax']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = gensim.models.Phrases(rev_data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[rev_data_words], threshold=100)\n",
        "\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out\n",
        "data_words_nostops = remove_stopwords(rev_data_words)\n",
        "\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YltvQNpZIWx",
        "outputId": "aaa7c985-f066-41bb-b5d7-7b3167fbf935"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['reference', 'rating', 'movie', 'despicable', 'star', 'despicable', 'star', 'minion', 'star', 'despicable', 'star', 'pleasantly', 'surprise', 'good', 'original', 'fire', 'cylinder', 'comedy', 'story', 'visual', 'action', 'scene', 'start', 'fast', 'never', 'let', 'movie', 'fly', 'ton', 'great', 'new', 'character', 'movie', 'absolutely', 'hilarious', 'literally', 'tear', 'scene', 'minion', 'well', 'many', 'memorable', 'moment', 'story', 'surprisingly', 'unpredictable', 'keep', 'invest', 'visual', 'stunningly', 'beautiful', 'mesmerized', 'action', 'scene', 'pretty', 'epic', 'good', 'entire', 'series', 'blast', 'movie', 'definitely', 'worth', 'see', 'premium', 'screen', 'greatly', 'enhance', 'visual', 'action', 'scene', 'sure', 'sarcastic', 'star', 'review', 'assure', 'viewing', 'open', 'thursday', 'imax', 'imax']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_id2word = corpora.Dictionary(data_lemmatized)\n",
        "review_texts = data_lemmatized\n",
        "review_corpus = [review_id2word.doc2bow(text) for text in review_texts]\n",
        "print(review_corpus[:1])\n",
        "[[(review_id2word[i], f) for i, f in c] for c in review_corpus[:1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b48kj75ZnIi",
        "outputId": "cb0a6dd3-88a2-46c0-b0fe-f49b3602175a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 3), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 3), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 4), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 4), (43, 1), (44, 1), (45, 1), (46, 5), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 3), (59, 1), (60, 1)]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('absolutely', 1),\n",
              "  ('action', 3),\n",
              "  ('assure', 1),\n",
              "  ('beautiful', 1),\n",
              "  ('blast', 1),\n",
              "  ('character', 1),\n",
              "  ('comedy', 1),\n",
              "  ('cylinder', 1),\n",
              "  ('definitely', 1),\n",
              "  ('despicable', 3),\n",
              "  ('enhance', 1),\n",
              "  ('entire', 1),\n",
              "  ('epic', 1),\n",
              "  ('fast', 1),\n",
              "  ('fire', 1),\n",
              "  ('fly', 1),\n",
              "  ('good', 2),\n",
              "  ('great', 1),\n",
              "  ('greatly', 1),\n",
              "  ('hilarious', 1),\n",
              "  ('imax', 2),\n",
              "  ('invest', 1),\n",
              "  ('keep', 1),\n",
              "  ('let', 1),\n",
              "  ('literally', 1),\n",
              "  ('many', 1),\n",
              "  ('memorable', 1),\n",
              "  ('mesmerized', 1),\n",
              "  ('minion', 2),\n",
              "  ('moment', 1),\n",
              "  ('movie', 4),\n",
              "  ('never', 1),\n",
              "  ('new', 1),\n",
              "  ('open', 1),\n",
              "  ('original', 1),\n",
              "  ('pleasantly', 1),\n",
              "  ('premium', 1),\n",
              "  ('pretty', 1),\n",
              "  ('rating', 1),\n",
              "  ('reference', 1),\n",
              "  ('review', 1),\n",
              "  ('sarcastic', 1),\n",
              "  ('scene', 4),\n",
              "  ('screen', 1),\n",
              "  ('see', 1),\n",
              "  ('series', 1),\n",
              "  ('star', 5),\n",
              "  ('start', 1),\n",
              "  ('story', 2),\n",
              "  ('stunningly', 1),\n",
              "  ('sure', 1),\n",
              "  ('surprise', 1),\n",
              "  ('surprisingly', 1),\n",
              "  ('tear', 1),\n",
              "  ('thursday', 1),\n",
              "  ('ton', 1),\n",
              "  ('unpredictable', 1),\n",
              "  ('viewing', 1),\n",
              "  ('visual', 3),\n",
              "  ('well', 1),\n",
              "  ('worth', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_id2word[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_jwWk4h0aGuQ",
        "outputId": "81ced1b0-ea4d-44d5-883c-144461b17f14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'absolutely'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the 'pprint' function for pretty-printing output.\n",
        "from pprint import pprint\n",
        "\n",
        "# Create an LDA (Latent Dirichlet Allocation) model using Gensim's 'ldamodel.LdaModel'.\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=review_corpus,  # The bag-of-words corpus of the text data.\n",
        "    id2word=review_id2word,  # The dictionary mapping word IDs to words.\n",
        "    num_topics=20,  # The number of topics to identify.\n",
        "    random_state=100,  # Set a random state for reproducibility.\n",
        "    update_every=1,  # How often to update the model.\n",
        "    chunksize=100,  # The number of documents to use in each training chunk.\n",
        "    passes=10,  # The number of times the entire corpus should be iterated.\n",
        "    alpha='auto',  # Automatic setting for the alpha hyperparameter.\n",
        "    per_word_topics=True  # Return per-word topic probabilities.\n",
        ")\n",
        "\n",
        "# Print the topics discovered by the LDA model.\n",
        "pprint(lda_model.print_topics())\n",
        "\n",
        "# Apply the LDA model to the document corpus to obtain topic distributions.\n",
        "doc_lda = lda_model[review_corpus]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOBcUZdyaLsQ",
        "outputId": "755349a6-5838-4d89-ea3e-17fc67643a20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.001*\"movie\" + 0.001*\"well\" + 0.001*\"work\" + 0.001*\"character\" + '\n",
            "  '0.001*\"still\" + 0.001*\"film\" + 0.001*\"gru\" + 0.001*\"fun\" + 0.001*\"get\" + '\n",
            "  '0.001*\"make\"'),\n",
            " (1,\n",
            "  '0.023*\"well\" + 0.019*\"time\" + 0.018*\"work\" + 0.017*\"moment\" + '\n",
            "  '0.017*\"character\" + 0.016*\"get\" + 0.013*\"quite\" + 0.013*\"lot\" + 0.013*\"fun\" '\n",
            "  '+ 0.013*\"movie\"'),\n",
            " (2,\n",
            "  '0.001*\"gru\" + 0.001*\"movie\" + 0.001*\"minion\" + 0.001*\"make\" + '\n",
            "  '0.001*\"character\" + 0.001*\"well\" + 0.001*\"film\" + 0.001*\"villain\" + '\n",
            "  '0.001*\"rise\" + 0.001*\"kid\"'),\n",
            " (3,\n",
            "  '0.001*\"movie\" + 0.001*\"character\" + 0.001*\"minion\" + 0.001*\"animation\" + '\n",
            "  '0.001*\"well\" + 0.001*\"rise\" + 0.001*\"make\" + 0.001*\"story\" + 0.001*\"work\" + '\n",
            "  '0.001*\"clearly\"'),\n",
            " (4,\n",
            "  '0.001*\"minion\" + 0.001*\"gru\" + 0.001*\"make\" + 0.001*\"rise\" + 0.001*\"get\" + '\n",
            "  '0.001*\"film\" + 0.001*\"character\" + 0.001*\"movie\" + 0.001*\"villain\" + '\n",
            "  '0.001*\"sure\"'),\n",
            " (5,\n",
            "  '0.026*\"minion\" + 0.016*\"movie\" + 0.016*\"star\" + 0.013*\"despicable\" + '\n",
            "  '0.013*\"get\" + 0.013*\"scene\" + 0.013*\"visual\" + 0.010*\"action\" + 0.010*\"gru\" '\n",
            "  '+ 0.010*\"story\"'),\n",
            " (6,\n",
            "  '0.063*\"movie\" + 0.031*\"minion\" + 0.029*\"despicable\" + 0.021*\"gru\" + '\n",
            "  '0.018*\"review\" + 0.016*\"rise\" + 0.016*\"story\" + 0.016*\"film\" + '\n",
            "  '0.014*\"child\" + 0.014*\"enough\"'),\n",
            " (7,\n",
            "  '0.041*\"minion\" + 0.037*\"gru\" + 0.033*\"make\" + 0.025*\"rise\" + '\n",
            "  '0.018*\"character\" + 0.016*\"villain\" + 0.014*\"movie\" + 0.014*\"film\" + '\n",
            "  '0.013*\"wild\" + 0.012*\"watch\"'),\n",
            " (8,\n",
            "  '0.002*\"movie\" + 0.002*\"minion\" + 0.002*\"voice\" + 0.002*\"film\" + '\n",
            "  '0.001*\"despicable\" + 0.001*\"gru\" + 0.001*\"story\" + 0.001*\"make\" + '\n",
            "  '0.001*\"work\" + 0.001*\"rise\"'),\n",
            " (9,\n",
            "  '0.018*\"film\" + 0.015*\"minion\" + 0.014*\"franchise\" + 0.013*\"well\" + '\n",
            "  '0.011*\"worth\" + 0.011*\"character\" + 0.010*\"see\" + 0.009*\"plot\" + '\n",
            "  '0.009*\"age\" + 0.009*\"find\"'),\n",
            " (10,\n",
            "  '0.001*\"movie\" + 0.001*\"moment\" + 0.001*\"well\" + 0.001*\"character\" + '\n",
            "  '0.001*\"work\" + 0.001*\"film\" + 0.001*\"still\" + 0.001*\"get\" + 0.001*\"fun\" + '\n",
            "  '0.001*\"quite\"'),\n",
            " (11,\n",
            "  '0.044*\"movie\" + 0.035*\"minion\" + 0.021*\"good\" + 0.019*\"make\" + 0.017*\"want\" '\n",
            "  '+ 0.013*\"villain\" + 0.013*\"love\" + 0.013*\"story\" + 0.013*\"well\" + '\n",
            "  '0.013*\"even\"'),\n",
            " (12,\n",
            "  '0.032*\"minion\" + 0.032*\"well\" + 0.022*\"time\" + 0.011*\"gru\" + 0.011*\"make\" + '\n",
            "  '0.011*\"film\" + 0.011*\"rise\" + 0.011*\"kid\" + 0.011*\"fun\" + 0.011*\"first\"'),\n",
            " (13,\n",
            "  '0.026*\"kid\" + 0.026*\"funny\" + 0.013*\"let\" + 0.013*\"movie\" + 0.013*\"short\" + '\n",
            "  '0.013*\"little\" + 0.013*\"get\" + 0.013*\"great\" + 0.013*\"minion\" + '\n",
            "  '0.013*\"animation\"'),\n",
            " (14,\n",
            "  '0.041*\"voice\" + 0.039*\"movie\" + 0.027*\"film\" + 0.027*\"minion\" + '\n",
            "  '0.019*\"make\" + 0.018*\"gru\" + 0.016*\"animation\" + 0.014*\"kid\" + 0.014*\"joke\" '\n",
            "  '+ 0.014*\"seem\"'),\n",
            " (15,\n",
            "  '0.002*\"minion\" + 0.002*\"movie\" + 0.002*\"franchise\" + 0.002*\"make\" + '\n",
            "  '0.001*\"even\" + 0.001*\"well\" + 0.001*\"kid\" + 0.001*\"consider\" + '\n",
            "  '0.001*\"people\" + 0.001*\"film\"'),\n",
            " (16,\n",
            "  '0.036*\"movie\" + 0.024*\"feel\" + 0.024*\"pretty\" + 0.024*\"well\" + 0.023*\"flat\" '\n",
            "  '+ 0.023*\"do\" + 0.023*\"trailer\" + 0.015*\"one\" + 0.013*\"original\" + '\n",
            "  '0.013*\"see\"'),\n",
            " (17,\n",
            "  '0.032*\"joke\" + 0.016*\"movie\" + 0.016*\"still\" + 0.016*\"theater\" + '\n",
            "  '0.016*\"reference\" + 0.016*\"many\" + 0.016*\"laugh\" + 0.016*\"slapstick\" + '\n",
            "  '0.016*\"innuendo\" + 0.016*\"seventy\"'),\n",
            " (18,\n",
            "  '0.001*\"movie\" + 0.001*\"star\" + 0.001*\"scene\" + 0.001*\"well\" + '\n",
            "  '0.001*\"visual\" + 0.001*\"moment\" + 0.001*\"despicable\" + 0.001*\"action\" + '\n",
            "  '0.001*\"minion\" + 0.001*\"film\"'),\n",
            " (19,\n",
            "  '0.031*\"movie\" + 0.031*\"minion\" + 0.016*\"deep\" + 0.016*\"gru\" + 0.016*\"mean\" '\n",
            "  '+ 0.016*\"way\" + 0.016*\"fun\" + 0.016*\"character\" + 0.016*\"see\" + '\n",
            "  '0.016*\"scene\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the coherence score for the LDA model using the 'CoherenceModel' from Gensim.\n",
        "coherence_model_lda = CoherenceModel(\n",
        "    model=lda_model,  # The LDA model to evaluate.\n",
        "    texts=data_lemmatized,  # The lemmatized text data.\n",
        "    dictionary=review_id2word,  # The dictionary mapping word IDs to words.\n",
        "    coherence='c_v'  # Specify the coherence measure to use ('c_v' in this case).\n",
        ")\n",
        "\n",
        "# Obtain the coherence score.\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "\n",
        "# Print the computed coherence score.\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCK2HUrFaSgV",
        "outputId": "91112061-f7a5-4e2d-de90-ca8470ef4c1b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.27223683930512543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Calculate coherence values for LDA models with varying numbers of topics.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Maximum number of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to LDA models with different numbers of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        # Create an LDA model with the specified number of topics.\n",
        "        model = gensim.models.ldamodel.LdaModel(\n",
        "            corpus=corpus,  # The bag-of-words corpus of the text data.\n",
        "            id2word=dictionary,  # The dictionary mapping word IDs to words.\n",
        "            num_topics=num_topics,  # Number of topics to identify.\n",
        "            random_state=100,  # Set a random state for reproducibility.\n",
        "            update_every=1,  # How often to update the model.\n",
        "            chunksize=100,  # The number of documents to use in each training chunk.\n",
        "            passes=10,  # The number of times the entire corpus should be iterated.\n",
        "            alpha='auto',  # Automatic setting for the alpha hyperparameter.\n",
        "            per_word_topics=True  # Return per-word topic probabilities.\n",
        "        )\n",
        "\n",
        "        model_list.append(model)\n",
        "\n",
        "        # Calculate the coherence score using the 'CoherenceModel' for the current model.\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        # Append the coherence value to the list.\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values\n",
        "\n",
        "# Specify parameters for the number of topics to evaluate.\n",
        "start, limit, step = 2, 20, 2\n",
        "# Call the 'compute_coherence_values' function to compute coherence values for various LDA models.\n",
        "model_list, coherence_values = compute_coherence_values(\n",
        "    dictionary=review_id2word,  # The dictionary mapping word IDs to words.\n",
        "    corpus=review_corpus,  # The bag-of-words corpus of the text data.\n",
        "    texts=data_lemmatized,  # The lemmatized text data.\n",
        "    start=start, limit=limit, step=step  # Parameters for the number of topics to evaluate.\n",
        ")\n",
        "\n",
        "# Store and print the computed coherence values for each number of topics.\n",
        "cohe_val = []\n",
        "for m, cv in zip(range(start, limit, step), coherence_values):\n",
        "    cohe_val.append(round(cv, 4))\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B89aM_qdbPyz",
        "outputId": "526e7836-1aa2-469c-b70b-93733ae37f00"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Topics = 2  has Coherence Value of 0.2493\n",
            "Num Topics = 4  has Coherence Value of 0.283\n",
            "Num Topics = 6  has Coherence Value of 0.2829\n",
            "Num Topics = 8  has Coherence Value of 0.3235\n",
            "Num Topics = 10  has Coherence Value of 0.3438\n",
            "Num Topics = 12  has Coherence Value of 0.2563\n",
            "Num Topics = 14  has Coherence Value of 0.2427\n",
            "Num Topics = 16  has Coherence Value of 0.3014\n",
            "Num Topics = 18  has Coherence Value of 0.3029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(cohe_val)/len(cohe_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJFD91nmbfyM",
        "outputId": "915a637f-d4e0-483d-ca38-3d1e73df762e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2873111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the optimal LDA model from the list of models (index 3 in this case, corresponding to 8 topics).\n",
        "optimal_model = model_list[3]\n",
        "\n",
        "# Get the topics of the chosen LDA model.\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "\n",
        "# Pretty-print the top 10 words for each topic in the LDA model.\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1oMZ7Hwbts7",
        "outputId": "8e8d5c5e-6dbf-464d-b8f1-3c32fdddb2bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.001*\"movie\" + 0.001*\"gru\" + 0.001*\"minion\" + 0.001*\"well\" + 0.001*\"film\" '\n",
            "  '+ 0.001*\"character\" + 0.001*\"make\" + 0.001*\"work\" + 0.001*\"still\" + '\n",
            "  '0.001*\"fun\"'),\n",
            " (1,\n",
            "  '0.019*\"movie\" + 0.015*\"minion\" + 0.014*\"get\" + 0.014*\"film\" + 0.013*\"well\" '\n",
            "  '+ 0.011*\"character\" + 0.011*\"work\" + 0.011*\"voice\" + 0.011*\"still\" + '\n",
            "  '0.010*\"moment\"'),\n",
            " (2,\n",
            "  '0.020*\"movie\" + 0.014*\"well\" + 0.014*\"feel\" + 0.014*\"pretty\" + 0.014*\"flat\" '\n",
            "  '+ 0.007*\"minion\" + 0.007*\"character\" + 0.007*\"kid\" + 0.007*\"fun\" + '\n",
            "  '0.007*\"story\"'),\n",
            " (3,\n",
            "  '0.020*\"movie\" + 0.016*\"minion\" + 0.011*\"well\" + 0.010*\"make\" + '\n",
            "  '0.010*\"character\" + 0.010*\"animation\" + 0.010*\"story\" + 0.010*\"original\" + '\n",
            "  '0.010*\"clearly\" + 0.006*\"film\"'),\n",
            " (4,\n",
            "  '0.012*\"remember\" + 0.012*\"however\" + 0.011*\"say\" + 0.010*\"watch\" + '\n",
            "  '0.010*\"year\" + 0.007*\"placate\" + 0.007*\"super\" + 0.007*\"portuguese\" + '\n",
            "  '0.007*\"ramble\" + 0.007*\"gibberish\"'),\n",
            " (5,\n",
            "  '0.020*\"movie\" + 0.015*\"minion\" + 0.014*\"kid\" + 0.012*\"star\" + '\n",
            "  '0.010*\"despicable\" + 0.010*\"see\" + 0.010*\"action\" + 0.010*\"new\" + '\n",
            "  '0.010*\"well\" + 0.008*\"story\"'),\n",
            " (6,\n",
            "  '0.046*\"movie\" + 0.031*\"minion\" + 0.016*\"voice\" + 0.014*\"kid\" + 0.014*\"film\" '\n",
            "  '+ 0.014*\"despicable\" + 0.012*\"make\" + 0.012*\"gru\" + 0.012*\"good\" + '\n",
            "  '0.011*\"rise\"'),\n",
            " (7,\n",
            "  '0.036*\"minion\" + 0.026*\"gru\" + 0.020*\"make\" + 0.017*\"film\" + 0.017*\"rise\" + '\n",
            "  '0.017*\"character\" + 0.013*\"movie\" + 0.013*\"well\" + 0.013*\"time\" + '\n",
            "  '0.009*\"fun\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "\n",
        "**Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import LsiModel\n",
        "\n",
        "lsamodel = LsiModel(review_corpus, num_topics=10, id2word = review_id2word)\n",
        "print(lsamodel.print_topics(num_topics=10, num_words=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiQFS_OKccC_",
        "outputId": "086c4f22-e04e-490f-d649-85bce97fa1e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.364*\"movie\" + 0.260*\"minion\" + 0.223*\"well\" + 0.211*\"film\" + 0.201*\"make\" + 0.194*\"character\" + 0.181*\"gru\" + 0.176*\"work\" + 0.169*\"get\" + 0.152*\"voice\"'), (1, '-0.445*\"minion\" + -0.262*\"gru\" + -0.197*\"villain\" + -0.174*\"rise\" + -0.171*\"make\" + 0.163*\"moment\" + -0.156*\"good\" + 0.128*\"quite\" + 0.126*\"balance\" + -0.120*\"sure\"'), (2, '-0.375*\"movie\" + 0.294*\"gru\" + -0.262*\"despicable\" + 0.219*\"make\" + -0.175*\"good\" + -0.158*\"story\" + 0.153*\"character\" + 0.147*\"wild\" + -0.136*\"think\" + 0.124*\"come\"'), (3, '-0.339*\"movie\" + 0.313*\"franchise\" + 0.250*\"film\" + 0.161*\"time\" + 0.152*\"minion\" + -0.133*\"villain\" + 0.130*\"fun\" + 0.127*\"least\" + 0.121*\"manage\" + 0.120*\"worth\"'), (4, '0.266*\"voice\" + 0.251*\"film\" + -0.203*\"kid\" + -0.190*\"see\" + -0.177*\"good\" + -0.145*\"make\" + 0.138*\"child\" + 0.137*\"enough\" + -0.132*\"get\" + -0.127*\"even\"'), (5, '0.199*\"good\" + -0.189*\"kid\" + -0.160*\"action\" + -0.152*\"worth\" + 0.147*\"even\" + -0.139*\"join\" + -0.127*\"voice\" + -0.127*\"new\" + -0.125*\"see\" + -0.124*\"return\"'), (6, '-0.360*\"voice\" + -0.279*\"get\" + 0.207*\"character\" + -0.156*\"minion\" + 0.144*\"scene\" + -0.144*\"vicious\" + 0.142*\"movie\" + 0.139*\"star\" + 0.135*\"feel\" + -0.134*\"join\"'), (7, '-0.319*\"kid\" + -0.301*\"funny\" + 0.204*\"good\" + -0.139*\"really\" + -0.139*\"short\" + -0.139*\"move\" + 0.137*\"star\" + 0.136*\"action\" + -0.136*\"let\" + -0.132*\"animation\"'), (8, '-0.369*\"star\" + -0.288*\"scene\" + -0.234*\"visual\" + -0.176*\"action\" + -0.149*\"get\" + -0.143*\"imax\" + 0.102*\"enough\" + -0.098*\"keep\" + -0.094*\"sure\" + -0.091*\"comedy\"'), (9, '0.379*\"voice\" + 0.187*\"seem\" + -0.171*\"get\" + 0.158*\"kid\" + 0.149*\"year\" + 0.126*\"make\" + 0.125*\"watch\" + 0.120*\"star\" + 0.116*\"bit\" + 0.108*\"scene\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_lsa_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Calculate coherence values for LSA models with varying numbers of topics.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Maximum number of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LSA models\n",
        "    coherence_values : Coherence values corresponding to LSA models with different numbers of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "\n",
        "    for num_topics in range(start, limit, step):\n",
        "        # Create an LSA model with the specified number of topics.\n",
        "        lsamodel = LsiModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        model_list.append(lsamodel)\n",
        "\n",
        "        # Calculate the coherence score using the 'CoherenceModel' for the current LSA model.\n",
        "        coherencemodel = CoherenceModel(model=lsamodel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "\n",
        "        # Append the coherence value to the list.\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    return model_list, coherence_values\n",
        "\n",
        "# Specify parameters for the number of topics to evaluate.\n",
        "start, limit, step = 2, 20, 2\n",
        "# Call the 'compute_lsa_coherence_values' function to compute coherence values for various LSA models.\n",
        "model_lsa, coherence_values = compute_lsa_coherence_values(\n",
        "    dictionary=review_id2word,  # The dictionary mapping word IDs to words.\n",
        "    corpus=review_corpus,  # The bag-of-words corpus of the text data.\n",
        "    texts=data_lemmatized,  # The lemmatized text data.\n",
        "    start=start, limit=limit, step=step  # Parameters for the number of topics to evaluate.\n",
        ")\n",
        "\n",
        "# Store and print the computed coherence values for each number of topics.\n",
        "coherence_values_all = []\n",
        "for m, cv in zip(range(start, limit, step), coherence_values):\n",
        "    coherence_values_all.append(round(cv, 4))\n",
        "    print(\"Topic no =\", m, \" it's Coherence Value is\", round(cv, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORlGn4FZcwsy",
        "outputId": "761f2fd6-edf2-470b-ed1b-ff099b8fe85a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic no = 2  it's Coherence Value is 0.243\n",
            "Topic no = 4  it's Coherence Value is 0.3322\n",
            "Topic no = 6  it's Coherence Value is 0.3568\n",
            "Topic no = 8  it's Coherence Value is 0.4069\n",
            "Topic no = 10  it's Coherence Value is 0.384\n",
            "Topic no = 12  it's Coherence Value is 0.3776\n",
            "Topic no = 14  it's Coherence Value is 0.3321\n",
            "Topic no = 16  it's Coherence Value is 0.3567\n",
            "Topic no = 18  it's Coherence Value is 0.4129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the coherence score for the LSA model using the 'CoherenceModel' from Gensim.\n",
        "coherencemodel = CoherenceModel(\n",
        "    model=lsamodel,  # The LSA model to evaluate.\n",
        "    texts=data_lemmatized,  # The lemmatized text data.\n",
        "    dictionary=review_id2word,  # The dictionary mapping word IDs to words.\n",
        "    coherence='c_v'  # Specify the coherence measure to use ('c_v' in this case).\n",
        ")\n",
        "\n",
        "# Print the computed coherence score.\n",
        "print(coherencemodel.get_coherence())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3RaRybydAMb",
        "outputId": "08b5fac2-1512-4ce0-f588-58d917debea3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.38244687108415276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_values_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR3yyKVCdEJm",
        "outputId": "63cf2865-123e-4f24-c5e6-8801b683d499"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.243, 0.3322, 0.3568, 0.4069, 0.384, 0.3776, 0.3321, 0.3567, 0.4129]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average coherence value by summing all the coherence values and dividing by the total number of values.\n",
        "average_coherence = sum(coherence_values_all) / len(coherence_values_all)\n",
        "\n",
        "# Print the computed average coherence value.\n",
        "print(\"Average Coherence Value:\", average_coherence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MurmhhEPdGZb",
        "outputId": "154c1e1c-d3aa-4fb7-ba30-067dbd8ae7e3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Coherence Value: 0.35580000000000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "**Generate K topics by using lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f155e07-0c88-48e8-fdc6-58c9de6ab12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting preprocess\n",
            "  Downloading preprocess-2.0.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from preprocess) (0.18.3)\n",
            "Installing collected packages: preprocess\n",
            "Successfully installed preprocess-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "nltk.download('all')\n",
        "!pip install preprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import pyLDAvis\n",
        "pyLDAvis.enable_notebook()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the number of top words to extract per topic.\n",
        "top_value = 10\n",
        "\n",
        "# Create a dictionary to store the top words for each topic.\n",
        "top_topic_words = {}\n",
        "\n",
        "# Loop through the topics and their associated words.\n",
        "for j, topic_to_word in enumerate(df.reviews.tolist()):\n",
        "    # Sort the words in descending order based on their importance in the topic.\n",
        "    top_words = np.argsort(topic_to_word)[::-1][:top_value]\n",
        "\n",
        "    # Prepare a message to display the topic and its top words.\n",
        "    msg = 'Topic %i ' % j\n",
        "    top_words_list = [df.reviews.tolist()[i].strip()[:35] for i in top_words]\n",
        "    msg += 'has stop words '.join(top_words_list)\n",
        "\n",
        "    # Print the message.\n",
        "    print(msg)\n",
        "\n",
        "    # Store the top words for the current topic in the dictionary.\n",
        "    top_topic_words[j] = top_words_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "DA12bqgleqTD",
        "outputId": "32c06434-f63c-45cc-9a94-0dec3d0e05d1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'reviews'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-314bfd87ab4d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Loop through the topics and their associated words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_to_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Sort the words in descending order based on their importance in the topic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_to_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5901\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mall\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequivalent\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5904\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlarger\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mall\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reviews'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "**Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Tvp3KogTLN",
        "outputId": "bf50cfe6-9778-4c7e-b597-81b111308931"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.25.2)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.33)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.6.1)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.38.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (9.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.10.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from bertopic import BERTopic\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Load text data\n",
        "data = fetch_20newsgroups(subset='all')['data']\n",
        "\n",
        "# Create BERTopic model\n",
        "topic_model = BERTopic()\n",
        "\n",
        "# Fit BERTopic model and select optimal number of topics\n",
        "topics, _ = topic_model.fit_transform(data)\n",
        "\n",
        "# Generate topics\n",
        "topic_model.get_topics()\n",
        "\n",
        "# Summarize topics\n",
        "topic_model.get_topic_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "WoGIzhZfiPmC",
        "outputId": "925255b6-573f-4d2e-de2a-a26a0ea8c275"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-57fb8ffdd781>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Fit BERTopic model and select optimal number of topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Generate topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    385\u001b[0m             self.embedding_model = select_backend(self.embedding_model,\n\u001b[1;32m    386\u001b[0m                                                   language=self.language)\n\u001b[0;32m--> 387\u001b[0;31m             embeddings = self._extract_embeddings(documents.Document.values.tolist(),\n\u001b[0m\u001b[1;32m    388\u001b[0m                                                   \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                                   \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m_extract_embeddings\u001b[0;34m(self, documents, images, method, verbose)\u001b[0m\n\u001b[1;32m   3291\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"document\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3293\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3294\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3295\u001b[0m             raise ValueError(\"Make sure to use an embedding model that can either embed documents\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/backend/_base.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, document, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mthat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mm\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \"\"\"\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/backend/_sentencetransformers.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, documents, verbose)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mthat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mm\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"token_embeddings\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    498\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 427\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3 (Alternative) - (10 points)**\n",
        "\n",
        "If you are unable to do the topic modeling using lda2vec, do the alternate question.\n",
        "\n",
        "Provide atleast 3 visualization for the topics generated by the BERTopic or LDA model. Explain each of the visualization in detail."
      ],
      "metadata": {
        "id": "Wslk2SYHML8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit BERTopic model and select optimal number of topics\n",
        "topics, _ = topic_model.fit_transform(data)\n",
        "\n",
        "# Visualizing Topic Distribution\n",
        "topic_model.visualize_distribution()\n",
        "\n",
        "# Visualizing Word Clouds for Topics\n",
        "topic_model.visualize_barchart()\n",
        "\n",
        "# Visualizing Topic T-SNE Plot\n",
        "topic_model.visualize_termite_plot()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m9E6rzpoijFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Question (5 Points)\n",
        "\n",
        "**Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.**\n",
        "\n",
        "**This question will compensate for any points deducted in this exercise. Maximum marks for the exercise is 40 points.**"
      ],
      "metadata": {
        "id": "d89ODUx3jjJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coherence: Coherence measures the semantic similarity between high-scoring words within each topic. Higher coherence indicates more coherent and interpretable topics. LDA and NMF typically produce topics with higher coherence compared to LSA and HDP because they model word co-occurrence patterns more explicitly.\n",
        "\n",
        "Interpretability: Interpretability refers to how easily human interpreters can understand and label the topics. LDA and NMF usually produce more interpretable topics because they provide clear word distributions for each topic, whereas LSA and HDP may yield more abstract or ambiguous topics.\n",
        "\n",
        "Robustness: Robustness measures the stability of the topics across different runs or datasets. LDA and NMF tend to be more robust compared to LSA and HDP, as they are less sensitive to variations in the input data and initialization parameters.\n",
        "\n",
        "Scalability: Scalability assesses the efficiency of the algorithm in handling large datasets. LSA and NMF are typically more scalable than LDA and HDP, as they involve simpler computations and require fewer resources.\n",
        "\n",
        "Based on these criteria, it is challenging to definitively declare one algorithm as \"better\" than the others universally. However, LDA and NMF are commonly preferred in practice due to their balance of coherence, interpretability, and robustness. LDA is particularly popular for its ability to model document-topic and topic-word distributions explicitly, making it easier to interpret and analyze. NMF is also favored for its simplicity and effectiveness in capturing non-linear relationships in the data.\n",
        "\n",
        "Ultimately, the choice of the best algorithm depends on the specific requirements of the task, such as the size of the dataset, the desired level of interpretability, and the computational resources available. It is recommended to experiment with multiple algorithms and evaluate their performance using domain-specific metrics to determine the most suitable approach for a particular application."
      ],
      "metadata": {
        "id": "agkkd5fqfk8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "Consider the following points in your response:\n",
        "\n",
        "**Learning Experience:** Describe your overall learning experience in working with text data and extracting features using various topic modeling algorithms. Did you understand these algorithms and did the implementations helped in grasping the nuances of feature extraction from text data.\n",
        "\n",
        "**Challenges Encountered:** Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, working with text data and implementing various topic modeling algorithms provided a valuable learning experience. Understanding the principles behind algorithms like Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF) helped me grasp the nuances of feature extraction from text data. Implementing these algorithms from scratch also deepened my understanding of how they operate and how they can be applied to extract meaningful information from unstructured text.\n",
        "\n",
        "Challenges Encountered:\n",
        "While working on this exercise, I encountered several challenges. One of the main difficulties was tuning the hyperparameters of the algorithms, such as the number of topics in LDA or the number of components in NMF, to achieve optimal results. Additionally, preprocessing the text data to remove noise and irrelevant information required careful consideration to ensure the quality of the extracted features. However, experimenting with different preprocessing techniques and parameter settings ultimately helped overcome these challenges.\n",
        "\n",
        "Relevance to Your Field of Study:\n",
        "This exercise is highly relevant to the field of Natural Language Processing (NLP). Topic modeling algorithms play a crucial role in NLP tasks such as document clustering, text summarization, and sentiment analysis. By learning how to implement and apply these algorithms effectively, I have gained valuable skills that can be applied to real-world NLP problems. Understanding feature extraction from text data is fundamental in NLP, and this exercise has provided practical experience in this area."
      ],
      "metadata": {
        "id": "eVIxR-jSfQvk"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}